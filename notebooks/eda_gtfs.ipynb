{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# GTFS Data Exploration\n",
    "Explore routes, stops, and schedule data from the GTFS feed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import folium\n",
    "from pathlib import Path\n",
    "import matplotlib.pyplot as plt\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "gtfs_path = Path(\"../data/raw_gtfs\")\n",
    "routes = pd.read_csv(gtfs_path / \"routes.txt\")\n",
    "stops = pd.read_csv(gtfs_path / \"stops.txt\")\n",
    "stop_times = pd.read_csv(gtfs_path / \"stop_times.txt\")\n",
    "trips = pd.read_csv(gtfs_path / \"trips.txt\")\n",
    "calendar = pd.read_csv(gtfs_path / \"calendar.txt\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# GTFS files are already loaded in cell 2 as DataFrames: routes, stops, stop_times, trips, and calendar.\n",
    "# No need to reload them here.\n",
    "print(\"GTFS files loaded:\", list(gtfs_path.iterdir()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "merged = (\n",
    "    stop_times\n",
    "    .merge(trips, on=\"trip_id\")\n",
    "    .merge(routes, on=\"route_id\")\n",
    "    .merge(stops, on=\"stop_id\")\n",
    ")\n",
    "merged[\"arrival_time\"] = pd.to_datetime(merged[\"arrival_time\"], errors='coerce')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The key GTFS tables have already been merged into the 'merged' DataFrame in cell 4.\n",
    "# 'merged' contains stop_times, trips, routes, and stops data.\n",
    "print(merged.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create GTFS-derived features\n",
    "merged['hour'] = merged['arrival_time'].dt.hour\n",
    "merged['minute'] = merged['arrival_time'].dt.minute\n",
    "merged['day_of_week'] = merged['arrival_time'].dt.dayofweek"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "map_center = [merged[\"stop_lat\"].mean(), merged[\"stop_lon\"].mean()]\n",
    "m = folium.Map(location=map_center, zoom_start=12)\n",
    "for _, row in merged.iterrows():\n",
    "    folium.CircleMarker(\n",
    "        location=[row[\"stop_lat\"], row[\"stop_lon\"]],\n",
    "        radius=2,\n",
    "        color=\"red\"\n",
    "    ).add_to(m)\n",
    "m"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from folium.plugins import HeatMap\n",
    "\n",
    "# Prepare data for heatmap: group by stop location and count occurrences\n",
    "stop_freq = merged.groupby(['stop_lat', 'stop_lon']).size().reset_index(name='count')\n",
    "heat_data = stop_freq[['stop_lat', 'stop_lon', 'count']].values.tolist()\n",
    "\n",
    "heatmap = folium.Map(location=map_center, zoom_start=12)\n",
    "HeatMap(heat_data, radius=8, max_zoom=13).add_to(heatmap)\n",
    "heatmap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the enriched GTFS DataFrame to CSV\n",
    "merged.to_csv(\"merged.csv\", index=False)\n",
    "\n",
    "# Optionally, save the stops heatmap as an HTML file\n",
    "heatmap.save(\"stops_heatmap.html\")\n",
    "\n",
    "# Dynamic time-based filtering: busiest stops at 7am and 5pm\n",
    "busiest_7am = (\n",
    "    merged[merged['hour'] == 7]\n",
    "    .groupby(['stop_id', 'stop_name'])\n",
    "    .size()\n",
    "    .reset_index(name='count')\n",
    "    .sort_values('count', ascending=False)\n",
    ")\n",
    "busiest_5pm = (\n",
    "    merged[merged['hour'] == 17]\n",
    "    .groupby(['stop_id', 'stop_name'])\n",
    "    .size()\n",
    "    .reset_index(name='count')\n",
    "    .sort_values('count', ascending=False)\n",
    ")\n",
    "\n",
    "print(\"Top 10 busiest stops at 7am:\")\n",
    "print(busiest_7am.head(10))\n",
    "print(\"\\nTop 10 busiest stops at 5pm:\")\n",
    "print(busiest_5pm.head(10))\n",
    "\n",
    "# Route-wise trip frequency analytics\n",
    "route_trip_freq = (\n",
    "    merged.groupby('route_id')['trip_id']\n",
    "    .nunique()\n",
    "    .reset_index(name='trip_count')\n",
    "    .sort_values('trip_count', ascending=False)\n",
    ")\n",
    "print(\"\\nRoute-wise trip frequency:\")\n",
    "print(route_trip_freq.head(10))\n",
    "\n",
    "# Identifying underserved areas using route density (number of unique routes per stop)\n",
    "stop_route_density = (\n",
    "    merged.groupby(['stop_id', 'stop_name', 'stop_lat', 'stop_lon'])['route_id']\n",
    "    .nunique()\n",
    "    .reset_index(name='unique_routes')\n",
    "    .sort_values('unique_routes')\n",
    ")\n",
    "print(\"\\nStops with lowest route density (potentially underserved):\")\n",
    "print(stop_route_density.head(10))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
